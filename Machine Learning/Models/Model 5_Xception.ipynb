{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Model 5_Xception.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lqoLRb-fB4DC","executionInfo":{"status":"ok","timestamp":1621267548951,"user_tz":-420,"elapsed":23394,"user":{"displayName":"Bangkit Parkhere","photoUrl":"","userId":"17101979417736185635"}},"outputId":"f331debe-a4bb-4bf7-f067-558291c65ef5"},"source":["# mount google drive\n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"NiOvcaeYq_ZZ"},"source":["import os\n","import tensorflow as tf\n","from tensorflow.keras import layers, Model, Input\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.applications.xception import Xception\n","from os import getcwd"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JLtEnayfrfgD","colab":{"base_uri":"https://localhost:8080/"},"outputId":"4e0a4447-4606-498b-b724-31ffc155ad91"},"source":["# use xception transfer learning with input shape 300,300\n","pre_trained=Xception(\n","    include_top=False,\n","    input_shape=(300,300,3),\n","    weights='imagenet'\n",")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/xception/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n","83689472/83683744 [==============================] - 1s 0us/step\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"1egYo7p2r1cI"},"source":["# no need to retrain the layers\n","for layer in pre_trained.layers:\n","  layer.trainable=False"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1kw_zKGjBTRv"},"source":["# combine the pre-trained layers with our self-built layers\n","inputs=Input(shape=(300,300,3))\n","x=pre_trained(inputs, training=False)\n","x=layers.GlobalAveragePooling2D()(x) # use global average pooling instead of flatten to make it faster\n","outputs=layers.Dense(1, activation='sigmoid')(x)\n","\n","model=Model(inputs,outputs)\n","model.compile(\n","    optimizer=tf.keras.optimizers.Adam(lr=0.01),\n","    loss='binary_crossentropy',\n","    metrics=['accuracy']\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xRRi3WwOr40e"},"source":["# x=layers.Flatten()(pre_trained.output)\n","# x=layers.Dense(1024, activation='relu')(x)\n","# x=layers.Dropout(0.2)(x)\n","# x=layers.Dense(1, activation='sigmoid')(x)\n","\n","# model=Model(pre_trained.input,x)\n","# model.compile(\n","#     optimizer=tf.keras.optimizers.Adam(lr=0.01),\n","#     loss='binary_crossentropy',\n","#     metrics=['accuracy']\n","# )"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VlMqrYz7sBq5"},"source":["TRAIN_DIR='/content/train'\n","VAL_DIR='/content/validation'\n","TEST_DIR='/content/test'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"F2Jf3Y7usC1w","outputId":"2d3d2b94-ae6a-4d08-8f6d-410e7e5e02a0"},"source":["# train_datagen=ImageDataGenerator(1./255)\n","# train_generator=train_datagen.flow_from_directory(\n","#     TRAIN_DIR,\n","#     target_size=(300,300),\n","#     batch_size=64,\n","#     class_mode='binary'\n","# )"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Found 57671 images belonging to 2 classes.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"RC8U-1yC-u2p","colab":{"base_uri":"https://localhost:8080/"},"outputId":"d719ef3e-c299-4460-d658-5eb7e0e9193a"},"source":["# do some augmentation techniques (meanwhile we just saved the non-augmented model as it gave better accuracy)\n","train_datagen=ImageDataGenerator(\n","    rotation_range=40,\n","    width_shift_range=0.2,\n","    height_shift_range=0.2,\n","    shear_range=0.2,\n","    zoom_range=0.2,\n","    horizontal_flip=True,\n","    fill_mode='nearest'\n",")\n","train_generator=train_datagen.flow_from_directory(\n","    TRAIN_DIR,\n","    target_size=(300,300),\n","    batch_size=64,\n","    class_mode='binary'\n",")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Found 57671 images belonging to 2 classes.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7szQ2XqTsIhd","outputId":"b7a5fd52-0fec-4d2e-ed11-f5c9d1be63e4"},"source":["validation_datagen=ImageDataGenerator(1./255)\n","validation_generator=validation_datagen.flow_from_directory(\n","    VAL_DIR,\n","    target_size=(300,300),\n","    batch_size=64,\n","    class_mode='binary'\n",")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Found 11860 images belonging to 2 classes.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"K8ah55axBH_k","outputId":"833aa87e-6b1a-4d61-acb2-e21ec5e30b26"},"source":["# import os\n","# from PIL import Image\n","# folder_path = '/content/test'\n","# lol=[]\n","# extensions = []\n","# for fldr in os.listdir(folder_path):\n","#     sub_folder_path = os.path.join(folder_path, fldr)\n","#     for filee in os.listdir(sub_folder_path):\n","#         file_path = os.path.join(sub_folder_path, filee)\n","#         print('** Path: {}  **'.format(file_path), end=\"\\r\", flush=True)\n","#         if file_path in lol:\n","#           continue\n","#         im = Image.open(file_path)\n","#         rgb_im = im.convert('RGB')\n","#         if filee.split('.')[1] not in extensions:\n","#             extensions.append(filee.split('.')[1])"],"execution_count":null,"outputs":[{"output_type":"stream","text":[""],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xkjntt3MsKLM","outputId":"98373bd2-0e95-45cd-e758-2ee14acbec27"},"source":["# train the model\n","history=model.fit_generator(\n","    train_generator,\n","    epochs=5,\n","    verbose=1,\n","    validation_data=validation_generator\n",")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n","  warnings.warn('`Model.fit_generator` is deprecated and '\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/5\n","902/902 [==============================] - ETA: 0s - loss: 1.4800 - accuracy: 0.9408"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/keras_preprocessing/image/image_data_generator.py:720: UserWarning: This ImageDataGenerator specifies `featurewise_center`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n","  warnings.warn('This ImageDataGenerator specifies '\n"],"name":"stderr"},{"output_type":"stream","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r902/902 [==============================] - 1243s 1s/step - loss: 1.4800 - accuracy: 0.9408 - val_loss: 0.5095 - val_accuracy: 0.9745\n","Epoch 2/5\n","902/902 [==============================] - 1247s 1s/step - loss: 1.1983 - accuracy: 0.9438 - val_loss: 1.3225 - val_accuracy: 0.9737\n","Epoch 3/5\n","902/902 [==============================] - 1228s 1s/step - loss: 1.1257 - accuracy: 0.9481 - val_loss: 0.8521 - val_accuracy: 0.9589\n","Epoch 4/5\n","902/902 [==============================] - 1222s 1s/step - loss: 0.9661 - accuracy: 0.9476 - val_loss: 0.6648 - val_accuracy: 0.9715\n","Epoch 5/5\n","902/902 [==============================] - 1230s 1s/step - loss: 0.9596 - accuracy: 0.9490 - val_loss: 0.8974 - val_accuracy: 0.9390\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mBNfw4WVqVvS","outputId":"f3c3b95e-7e5d-4a10-f8d1-7093684facda"},"source":["test_datagen=ImageDataGenerator(1./255)\n","test_generator=test_datagen.flow_from_directory(\n","    TEST_DIR,\n","    target_size=(300,300),\n","    batch_size=64,\n","    class_mode='binary'\n",")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Found 18220 images belonging to 2 classes.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"x7SjG5vBqWkT","outputId":"38b62014-559d-478a-be1c-01018cc13b05"},"source":["# evaluate the model with test data\n","loss,acc=model.evaluate(test_generator, verbose=2)\n","print(acc)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/keras_preprocessing/image/image_data_generator.py:720: UserWarning: This ImageDataGenerator specifies `featurewise_center`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n","  warnings.warn('This ImageDataGenerator specifies '\n"],"name":"stderr"},{"output_type":"stream","text":["285/285 - 146s - loss: 2.3385 - accuracy: 0.8650\n","0.8649835586547852\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"_zuiCIsbs5gZ"},"source":["# save it into .h5 format\n","model.save('/content/drive/MyDrive/models/saved_model/xception_new_aug.h5')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"h8GpusV77oKB"},"source":[""],"execution_count":null,"outputs":[]}]}